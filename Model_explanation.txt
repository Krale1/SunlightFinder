Sunlight Finder - Model Evaluation Results (Real Numbers)
====================================================

Testing Methodology
------------------
1. Dataset Preparation:
   - Dataset size: 1416 samples
   - Features: latitude, longitude, hour, outdoor_seating, sun_bar_angle_diff
   - Target distribution: {0: 0.577683615819209, 1: 0.422316384180791}
   - Train/Test split: 75%/25%
   - Cross-validation: 5-fold

Model Testing Results
-------------------

Random Forest
Accuracy: 91.8%
Precision (Sun/No Sun): 91.6%/91.9%
Recall (Sun/No Sun): 87.0%/94.9%
F1-score (Sun/No Sun): 89.2%/93.4%
Avg. Prediction Time: 2.04ms
Model Size: 1.6MB
Training Time: 0.1s
Cross-validation Score: 92.6% (�2.0%)

Feature Importance:
   hour: 67.3%
   sun_bar_angle_diff: 14.0%
   longitude: 9.6%
   latitude: 8.2%
   outdoor_seating: 0.9%

XGBoost
Accuracy: 93.5%
Precision (Sun/No Sun): 92.6%/94.1%
Recall (Sun/No Sun): 90.6%/95.4%
F1-score (Sun/No Sun): 91.6%/94.7%
Avg. Prediction Time: 2.05ms
Model Size: 0.2MB
Training Time: 0.1s
Cross-validation Score: 91.9% (�1.7%)

Feature Importance:
   hour: 69.7%
   latitude: 8.6%
   longitude: 7.6%
   outdoor_seating: 7.3%
   sun_bar_angle_diff: 6.8%

LightGBM
Accuracy: 93.5%
Precision (Sun/No Sun): 93.2%/93.7%
Recall (Sun/No Sun): 89.9%/95.8%
F1-score (Sun/No Sun): 91.5%/94.7%
Avg. Prediction Time: 1.07ms
Model Size: 0.3MB
Training Time: 0.2s
Cross-validation Score: 92.8% (�1.6%)

Feature Importance:
   sun_bar_angle_diff: 76100.0%
   latitude: 75900.0%
   hour: 67800.0%
   longitude: 67100.0%
   outdoor_seating: 3200.0%

SVM
Accuracy: 59.0%
Precision (Sun/No Sun): 46.7%/64.3%
Recall (Sun/No Sun): 35.5%/74.1%
F1-score (Sun/No Sun): 40.3%/68.8%
Avg. Prediction Time: 0.44ms
Model Size: 0.1MB
Training Time: 0.1s
Cross-validation Score: 60.2% (�1.7%)

Neural Network
Accuracy: 90.7%
Precision (Sun/No Sun): 92.0%/90.0%
Recall (Sun/No Sun): 83.3%/95.4%
F1-score (Sun/No Sun): 87.5%/92.6%
Avg. Prediction Time: 0.43ms
Model Size: 0.0MB
Training Time: 0.2s
Cross-validation Score: 90.9% (�1.7%)

Logistic Regression
Accuracy: 59.3%
Precision (Sun/No Sun): 46.9%/64.1%
Recall (Sun/No Sun): 33.3%/75.9%
F1-score (Sun/No Sun): 39.0%/69.5%
Avg. Prediction Time: 0.61ms
Model Size: 0.0MB
Training Time: 0.0s
Cross-validation Score: 58.5% (�1.4%)

Feature Importance:
   longitude: 37.2%
   outdoor_seating: 23.0%
   latitude: 18.6%
   hour: 3.2%
   sun_bar_angle_diff: 0.8%


Model Selection Analysis
----------------------

Best performing model: XGBoost (93.5% accuracy)

Model Comparison:

Random Forest:
  - Accuracy: 91.8%
  - Prediction Time: 2.04ms
  - Model Size: 1.6MB
  - Training Time: 0.1s

XGBoost:
  - Accuracy: 93.5%
  - Prediction Time: 2.05ms
  - Model Size: 0.2MB
  - Training Time: 0.1s

LightGBM:
  - Accuracy: 93.5%
  - Prediction Time: 1.07ms
  - Model Size: 0.3MB
  - Training Time: 0.2s

SVM:
  - Accuracy: 59.0%
  - Prediction Time: 0.44ms
  - Model Size: 0.1MB
  - Training Time: 0.1s

Neural Network:
  - Accuracy: 90.7%
  - Prediction Time: 0.43ms
  - Model Size: 0.0MB
  - Training Time: 0.2s

Logistic Regression:
  - Accuracy: 59.3%
  - Prediction Time: 0.61ms
  - Model Size: 0.0MB
  - Training Time: 0.0s

Recommendations:
1. Consider the trade-off between accuracy and computational efficiency
2. Evaluate model performance in real-world conditions
3. Consider model interpretability and maintenance requirements
4. Test model performance with different feature combinations

Why XGBoost
Higher Accuracy:
 – XGBoost (and LightGBM) achieve 93.5% accuracy (compared to Random Forest’s 91.8%).
 – This means your sunlight predictions are more reliable and precise.
Smaller Model Size:
 – XGBoost’s model is only 0.2MB (versus Random Forest’s 1.6MB).
 – A smaller model is easier to deploy, update, and maintain.
Fast Predictions:
 – Although XGBoost’s prediction time (2.05ms) is slightly slower than LightGBM (1.07ms), it’s still very fast and efficient.
 – (If you prefer the fastest predictions, LightGBM is an equally great alternative.)
Better Handling of Non-Linear Relationships:
 – XGBoost (and LightGBM) excel at capturing complex interactions (for example, between “hour” and “sun_bar_angle_diff”) that are crucial for sunlight prediction.
Easy Maintenance & Retraining:
 – XGBoost is robust, well-documented, and easy to retrain as your dataset grows.